import os
import logging
import asyncio
import json
import base64
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv
from google import genai
from google.genai import types
from fastmcp import Client
import uvicorn

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
MCP_SERVER_URL = "http://localhost:8002/sse"
mcp_client = None

# -----------------------------------------------------------------------------
# Model Manager: AI ëª¨ë¸ ê´€ë¦¬ ë° í´ë°± ë¡œì§
# -----------------------------------------------------------------------------
class ModelManager:
    def __init__(self, api_key: str):
        self.client = genai.Client(api_key=api_key)
        # ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ì—…
        self.text_models = [
            "gemini-2.0-flash",
            "gemini-1.5-flash",
            "gemini-1.5-flash-001",
            "gemini-1.5-pro",
            "gemini-pro"
        ]
        self.image_model = "imagen-3.0-generate-001"
    
    async def generate_text(self, prompt: str, system_instr: str, tools: list = None):
        """í…ìŠ¤íŠ¸ ìƒì„± (Quota Exceeded ì‹œ ë‹¤ìŒ ëª¨ë¸ë¡œ ìë™ ì „í™˜)"""
        last_error = None
        
        for model_name in self.text_models:
            try:
                logger.info(f"ğŸ§  ì‹œë„ ì¤‘ì¸ ëª¨ë¸: {model_name}")
                
                config = types.GenerateContentConfig(
                    system_instruction=system_instr,
                    temperature=1.0, # ë§¤ë²ˆ ë‹¤ë¥¸ ì¶”ì²œì„ ìœ„í•´ ì°½ì˜ì„± ìµœëŒ€í™”
                    tools=tools
                )
                
                response = await self.client.aio.models.generate_content(
                    model=model_name,
                    contents=prompt,
                    config=config
                )
                
                logger.info(f"âœ… ìƒì„± ì„±ê³µ ({model_name})")
                return response.text
                
            except Exception as e:
                error_msg = str(e)
                logger.warning(f"âš ï¸ ëª¨ë¸ ì‹¤íŒ¨ ({model_name}): {error_msg}")
                # 429 Quota ë˜ëŠ” 404 Not Found ì‹œ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                if any(k in error_msg for k in ["429", "quota", "404", "not found", "NOT_FOUND"]):
                    logger.info(f"ğŸ”„ ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€ ({model_name}), ë‹¤ìŒ ëª¨ë¸ë¡œ ì „í™˜í•©ë‹ˆë‹¤...")
                    continue
                else:
                    # ë‹¤ë¥¸ ì—ëŸ¬ë©´ ë°”ë¡œ ì‹¤íŒ¨ ì²˜ë¦¬ (ë„êµ¬ ì‹¤í–‰ ì—ëŸ¬ ë“±)
                    last_error = e
                    break
        
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ
        if last_error:
            raise last_error
        raise HTTPException(status_code=500, detail="All AI models are busy or exhausted.")

    async def generate_image(self, prompt: str) -> str | None:
        # ì‚¬ìš©ìê°€ ì´ë¯¸ì§€ ìƒì„±ì„ ì›í•˜ì§€ ì•ŠìŒ
        return None 

# ì „ì—­ ëª¨ë¸ ë§¤ë‹ˆì € ë° í´ë¼ì´ì–¸íŠ¸
ai_manager = None
mcp_client = None

async def ensure_mcp_connection():
    """MCP ì„œë²„ ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•˜ê³ , ëŠì–´ì ¸ ìˆìœ¼ë©´ ì¬ì—°ê²°í•©ë‹ˆë‹¤."""
    global mcp_client
    try:
        # 1. í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„± ë° ì—°ê²°
        if not mcp_client:
            logger.info("ğŸ”Œ MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ì—°ê²° ì‹œë„...")
            mcp_client = Client(MCP_SERVER_URL)
            await mcp_client.__aenter__()
            logger.info("âœ… MCP ì„œë²„ ì‹ ê·œ ì—°ê²° ì„±ê³µ")
            return

        # 2. í´ë¼ì´ì–¸íŠ¸ëŠ” ìˆì§€ë§Œ ì„¸ì…˜ì´ ì—†ëŠ” ê²½ìš° (ì—°ê²° ëŠê¹€)
        # ì£¼ì˜: Client êµ¬í˜„ì— ë”°ë¼ session ì ‘ê·¼ ì‹œ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ tryë¡œ ê°ìŒˆ
        try:
            if not mcp_client.session:
                raise Exception("Session is None")
        except:
            logger.info("ğŸ”Œ MCP ì„œë²„ ì¬ì—°ê²° ì‹œë„...")
            # ê¸°ì¡´ ì—°ê²° ì •ë¦¬ ì‹œë„
            try:
                await mcp_client.__aexit__(None, None, None)
            except:
                pass
            
            # ë‹¤ì‹œ ì—°ê²°
            await mcp_client.__aenter__()
            logger.info("âœ… MCP ì„œë²„ ì¬ì—°ê²° ì„±ê³µ")
            
    except Exception as e:
        logger.error(f"âŒ MCP ì¬ì—°ê²° ì‹¤íŒ¨: {e}")
        # ì—°ê²° ê°œì²´ê°€ ê¹¨ì¡Œì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ˆê¸°í™”
        try:
            if mcp_client:
                await mcp_client.__aexit__(None, None, None)
        except:
            pass
        mcp_client = None  # ë‹¤ìŒ ìš”ì²­ ë•Œ ìƒˆë¡œ ìƒì„±í•˜ë„ë¡ ìœ ë„

# -----------------------------------------------------------------------------
# FastAPI Lifespan
# -----------------------------------------------------------------------------
@asynccontextmanager
async def lifespan(app: FastAPI):
    global mcp_client, ai_manager
    
    # AI Manager ì´ˆê¸°í™”
    ai_manager = ModelManager(GEMINI_API_KEY)
    
    # ì´ˆê¸° ì—°ê²° ì‹œë„
    await ensure_mcp_connection()
    
    yield
    
    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    if mcp_client:
        logger.info("ğŸ”Œ MCP ì„œë²„ ì—°ê²° í•´ì œ...")
        try:
            await mcp_client.__aexit__(None, None, None)
        except:
            pass

# 2. FastAPI ì•± ìƒì„±
app = FastAPI(title="AI Stylist API", lifespan=lifespan)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# 3. ë°ì´í„° êµ¬ì¡°
class ChatRequest(BaseModel):
    query: str
    include_image: bool = False # ê¸°ë³¸ê°’ Falseë¡œ ë³€ê²½

# 4. ì—”ë“œí¬ì¸íŠ¸
@app.get("/members")
async def get_members():
    try:
        # ì—°ê²° ë³´ì¥
        await ensure_mcp_connection()
        
        # ì´ë¯¸ ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
        result = await mcp_client.call_tool("get_team_members")
        
        # ë””ë²„ê¹… ë¡œê·¸
        logger.info(f"MCP Result Type: {type(result)}")
        logger.info(f"MCP Result Content: {result}")
        
        # CallToolResult êµ¬ì¡° ì²˜ë¦¬
        if result and hasattr(result, 'content') and result.content:
            first_content = result.content[0]
            if hasattr(first_content, 'text'):
                data_str = first_content.text
                try:
                    return json.loads(data_str)
                except json.JSONDecodeError:
                    # í…ìŠ¤íŠ¸ê°€ JSONì´ ì•„ë‹ ê²½ìš° (ì˜ˆ: ì—ëŸ¬ ë©”ì‹œì§€)
                    logger.error(f"JSON Parsing Failed: {data_str}")
                    return []
            # text ì†ì„±ì´ ì—†ì§€ë§Œ content ìì²´ê°€ ë°ì´í„°ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„ (êµ¬ì¡°ì— ë”°ë¼ ë‹¤ë¦„)
            
        return []
    except Exception as e:
        logger.error(f"Backend Error in get_members: {e}")
        return []

@app.post("/chat")
async def chat_endpoint(request: ChatRequest):
    logger.info(f"ğŸ“¨ ìš”ì²­: {request.query}")
    
    try:
        if not mcp_client or not mcp_client.session:
             raise HTTPException(status_code=503, detail="MCP Server not connected")

        # 1) í…ìŠ¤íŠ¸ ìƒì„± (Context ê¸°ë°˜)
        system_prompt = """
        ë‹¹ì‹ ì€ ì°½ì˜ì ì´ê³  ê°ê°ì ì¸ íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
        ì‚¬ìš©ìê°€ ì œê³µí•œ ìƒí™©(ìœ„ì¹˜, ë‚ ì”¨, ìš”ì¼, ê³„ì ˆ ë“±)ì„ ë°”íƒ•ìœ¼ë¡œ ìµœê³ ì˜ ë°ì¼ë¦¬ ë£©ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
        
        [ì¤‘ìš” ì§€ì¹¨]
        1. **ë‹¤ì–‘ì„±**: ê°™ì€ ì§ˆë¬¸ì´ë¼ë„ ë§¤ë²ˆ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼, ë‹¤ë¥¸ ì˜· ì¡°í•©ì„ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.
        2. **êµ¬ì²´ì„±**: ìƒì˜, í•˜ì˜, ì‹ ë°œ, ì•¡ì„¸ì„œë¦¬ê¹Œì§€ êµ¬ì²´ì ì¸ ì•„ì´í…œê³¼ ìƒ‰ìƒì„ ì§€ì •í•´ì£¼ì„¸ìš”.
        3. **ì´ìœ **: í•´ë‹¹ ì½”ë””ë¥¼ ì¶”ì²œí•œ ì´ìœ ë¥¼ ë‚ ì”¨ë‚˜ ìƒí™©ê³¼ ì—°ê²°ì§€ì–´ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        """
        
        full_response = await ai_manager.generate_text(
            prompt=request.query,
            system_instr=system_prompt,
            # tools=[mcp_client.session]  <-- ì œê±°: ì´ë¯¸ Queryì— ëª¨ë“  ì •ë³´ê°€ ìˆìœ¼ë¯€ë¡œ ë¶ˆí•„ìš”
        )
        
        return {
            "text": full_response,
            "image": None
        }

    except Exception as e:
        logger.error(f"Using AI Failed: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8004)
